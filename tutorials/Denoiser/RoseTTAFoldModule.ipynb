{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f441802-d387-433f-8b80-52005797daa2",
   "metadata": {},
   "source": [
    "# Enverionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ec38a8-89f4-47fe-a4d8-7d4bd964a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# change to ur local dir where 'Sampler' located\"\n",
    "base_dir = \"/data/hujing\"\n",
    "working_dir = os.path.join(base_dir, \"RFantibody\")\n",
    "\n",
    "sys.path.append(os.path.join(working_dir, \"src/rfantibody\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32afb09a-de9a-48db-bd06-cd0f1f8271ef",
   "metadata": {},
   "source": [
    "* We've known how the forward process implemented and we need the reverse process --> \"denoised process\" to push the noisy coordinated to meaningful structures.\n",
    "* According to RFAntibody code, the authors use the architecture of RoseTTAFold2 to re-construct the 3D-structure. So let's dive into the model framework firstly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae0c71f-737a-420e-b6e9-f4129fd01d2a",
   "metadata": {},
   "source": [
    "* [Inputs for the models, Page 17](https://www.biorxiv.org/content/10.1101/2024.03.14.585103v1.supplementary-material?versioned=true):\n",
    "  * MSA (virtual)\n",
    "  * Masked sequence\n",
    "  * noised_coordinates\n",
    "  * residue idx\n",
    "  * time_step T\n",
    "  * and some prcessed features\n",
    "\n",
    "* Let's check how the features are processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d237ff2-3780-40ad-a106-d92932c555f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You're overriding the checkpoint path from the defaults. Check that the model you're providing can run with the inputs you're providing.\n",
      "This is inf_conf.ckpt_path\n",
      "/data/hujing/RFantibody/weights/RFdiffusion_Ab.pt\n",
      "Assembling -model, -diffuser and -preprocess configs from checkpoint\n",
      "USING MODEL CONFIG: self._conf[model][SE3_param_full] = {'num_layers': 1, 'num_channels': 32, 'num_degrees': 2, 'n_heads': 4, 'div': 4, 'l0_in_features': 8, 'l0_out_features': 8, 'l1_in_features': 3, 'l1_out_features': 2, 'num_edge_features': 32}\n",
      "USING MODEL CONFIG: self._conf[model][SE3_param_topk] = {'num_layers': 1, 'num_channels': 32, 'num_degrees': 2, 'n_heads': 4, 'div': 4, 'l0_in_features': 64, 'l0_out_features': 64, 'l1_in_features': 3, 'l1_out_features': 2, 'num_edge_features': 64}\n",
      "USING MODEL CONFIG: self._conf[model][d_hidden] = 32\n",
      "USING MODEL CONFIG: self._conf[model][d_hidden_templ] = 32\n",
      "USING MODEL CONFIG: self._conf[model][d_msa] = 256\n",
      "USING MODEL CONFIG: self._conf[model][d_msa_full] = 64\n",
      "USING MODEL CONFIG: self._conf[model][d_pair] = 128\n",
      "USING MODEL CONFIG: self._conf[model][d_templ] = 64\n",
      "USING MODEL CONFIG: self._conf[model][d_time_emb] = 0\n",
      "USING MODEL CONFIG: self._conf[model][d_time_emb_proj] = 10\n",
      "USING MODEL CONFIG: self._conf[model][freeze_track_motif] = False\n",
      "WARNING: config model.input_seq_onehot is not saved in the checkpoint. Check that conf.model.input_seq_onehot = False is correct\n",
      "USING MODEL CONFIG: self._conf[model][n_extra_block] = 4\n",
      "USING MODEL CONFIG: self._conf[model][n_head_msa] = 8\n",
      "USING MODEL CONFIG: self._conf[model][n_head_pair] = 4\n",
      "USING MODEL CONFIG: self._conf[model][n_head_templ] = 4\n",
      "USING MODEL CONFIG: self._conf[model][n_main_block] = 32\n",
      "USING MODEL CONFIG: self._conf[model][n_ref_block] = 4\n",
      "USING MODEL CONFIG: self._conf[model][p_drop] = 0.15\n",
      "USING MODEL CONFIG: self._conf[model][use_motif_timestep] = True\n",
      "USING MODEL CONFIG: self._conf[diffuser][T] = 200\n",
      "USING MODEL CONFIG: self._conf[diffuser][aa_decode_steps] = 0\n",
      "USING MODEL CONFIG: self._conf[diffuser][b_0] = 0.01\n",
      "USING MODEL CONFIG: self._conf[diffuser][b_T] = 0.07\n",
      "USING MODEL CONFIG: self._conf[diffuser][chi_type] = interp\n",
      "USING MODEL CONFIG: self._conf[diffuser][crd_scale] = 0.25\n",
      "USING MODEL CONFIG: self._conf[diffuser][max_b] = 2.5\n",
      "USING MODEL CONFIG: self._conf[diffuser][max_sigma] = 1.5\n",
      "USING MODEL CONFIG: self._conf[diffuser][min_b] = 1.5\n",
      "USING MODEL CONFIG: self._conf[diffuser][min_sigma] = 0.02\n",
      "WARNING: config diffuser.partial_T is not saved in the checkpoint. Check that conf.diffuser.partial_T = None is correct\n",
      "WARNING: config diffuser.schedule_kwargs is not saved in the checkpoint. Check that conf.diffuser.schedule_kwargs = {} is correct\n",
      "USING MODEL CONFIG: self._conf[diffuser][schedule_type] = linear\n",
      "USING MODEL CONFIG: self._conf[diffuser][so3_schedule_type] = linear\n",
      "USING MODEL CONFIG: self._conf[diffuser][so3_type] = igso3\n",
      "WARNING: config seq_diffuser.loss_type is not saved in the checkpoint. Check that conf.seq_diffuser.loss_type = None is correct\n",
      "WARNING: config seq_diffuser.s_b0 is not saved in the checkpoint. Check that conf.seq_diffuser.s_b0 = None is correct\n",
      "WARNING: config seq_diffuser.s_bT is not saved in the checkpoint. Check that conf.seq_diffuser.s_bT = None is correct\n",
      "WARNING: config seq_diffuser.schedule_type is not saved in the checkpoint. Check that conf.seq_diffuser.schedule_type = None is correct\n",
      "WARNING: config seq_diffuser.seqdiff is not saved in the checkpoint. Check that conf.seq_diffuser.seqdiff = None is correct\n",
      "USING MODEL CONFIG: self._conf[preprocess][d_t1d] = 23\n",
      "USING MODEL CONFIG: self._conf[preprocess][d_t2d] = 45\n",
      "WARNING: config preprocess.hotspot_dim is not saved in the checkpoint. Check that conf.preprocess.hotspot_dim = 23 is correct\n",
      "USING MODEL CONFIG: self._conf[preprocess][motif_sidechain_input] = False\n",
      "WARNING: config preprocess.msaprev_bugfix is not saved in the checkpoint. Check that conf.preprocess.msaprev_bugfix = True is correct\n",
      "USING MODEL CONFIG: self._conf[preprocess][predict_previous] = False\n",
      "USING MODEL CONFIG: self._conf[preprocess][prob_self_cond] = 0.5\n",
      "USING MODEL CONFIG: self._conf[preprocess][selfcondition_msaprev] = True\n",
      "USING MODEL CONFIG: self._conf[preprocess][selfcondition_pairprev] = False\n",
      "USING MODEL CONFIG: self._conf[preprocess][selfcondition_stateprev] = False\n",
      "USING MODEL CONFIG: self._conf[preprocess][seq_self_cond] = False\n",
      "USING MODEL CONFIG: self._conf[preprocess][sequence_decode] = True\n",
      "USING MODEL CONFIG: self._conf[preprocess][sidechain_input] = False\n",
      "USING MODEL CONFIG: self._conf[preprocess][str_self_cond] = True\n",
      "WARNING: config preprocess.use_selfcond_emb is not saved in the checkpoint. Check that conf.preprocess.use_selfcond_emb = False is correct\n",
      "USING MODEL CONFIG: self._conf[antibody][T_scheme] = single_T_correct_selfcond\n",
      "WARNING: config antibody.correct_selfcond is not saved in the checkpoint. Check that conf.antibody.correct_selfcond = False is correct\n",
      "WARNING: config antibody.design_loops is not saved in the checkpoint. Check that conf.antibody.design_loops = ['H3:5-13'] is correct\n",
      "WARNING: config antibody.framework_pdb is not saved in the checkpoint. Check that conf.antibody.framework_pdb = /data/hujing/RFantibody/scripts/examples/example_inputs/hu-4D5-8_Fv.pdb is correct\n",
      "WARNING: config antibody.hotspot_termination_failures_permitted is not saved in the checkpoint. Check that conf.antibody.hotspot_termination_failures_permitted = 20 is correct\n",
      "WARNING: config antibody.hotspot_termination_threshold is not saved in the checkpoint. Check that conf.antibody.hotspot_termination_threshold = 10 is correct\n",
      "USING MODEL CONFIG: self._conf[antibody][no_bugfix_t1d_mask] = False\n",
      "WARNING: config antibody.target_pdb is not saved in the checkpoint. Check that conf.antibody.target_pdb = /data/hujing/RFantibody/scripts/examples/example_inputs/rsv_site3.pdb is correct\n",
      "WARNING: config antibody.terminate_bad_targeting is not saved in the checkpoint. Check that conf.antibody.terminate_bad_targeting = None is correct\n",
      "WARNING: You are changing diffuser.T from the value this model was trained with. Are you sure you know what you are doing?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| 'Doing AR Sequence Decoding'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      " \n",
      "WARNING: The following options are not currently implemented at inference. Decide if this matters.\n",
      "Delete these in inference/model_runners.py once they are implemented/once you decide they are not required for inference -- JW\n",
      " -predict_previous\n",
      " -prob_self_cond\n",
      " -seqdiff_b0\n",
      " -seqdiff_bT\n",
      " -seqdiff_schedule_type\n",
      " -seqdiff\n",
      " -freeze_track_motif\n",
      " -use_motif_timestep\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      " \n",
      "Successful diffuser __init__\n"
     ]
    }
   ],
   "source": [
    "# Firstly, we need to load some parameters. For sinplicity, we've prepared a yaml file which provides all parameters we need.\n",
    "# One can change the yaml file for the file path parameters.\n",
    "\n",
    "from rfantibody.rfdiffusion.inference import model_runners\n",
    "from rfantibody.rfdiffusion.inference.ab_util import featurize\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "\n",
    "config_path = \"/data/hujing/RFantibody/\" # change to your own yaml dir on ur PC\n",
    "config_name = \"init_conf\"\n",
    "\n",
    "with hydra.initialize_config_dir(config_dir=config_path):\n",
    "    conf = hydra.compose(config_name=config_name)\n",
    "\n",
    "# initialize the sampler for antibody\n",
    "ckpt_path = \"/data/hujing/RFantibody/weights/RFdiffusion_Ab.pt\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#ckpt = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "sampler = model_runners.AbSampler(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602605d5-7faa-4ec1-8826-2fc648239316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.pose.length(): 474\n",
      "ic| self.pose.binder_len(): 223\n",
      "ic| self.pose.L.seq: array([ 3,  9,  5, 12, 16,  5, 15, 14, 15, 15, 10, 15,  0, 15, 19,  7,  3,\n",
      "                             1, 19, 16,  9, 16,  4,  1,  0, 15,  5,  3, 19,  2, 16,  0, 19,  0,\n",
      "                            17, 18,  5,  5, 11, 14,  7, 11,  0, 14, 11, 10, 10,  9, 18, 15,  0,\n",
      "                            15, 13, 10, 18, 15,  7, 19, 14, 15,  1, 13, 15,  7, 15,  1, 15,  7,\n",
      "                            16,  3, 13, 16, 10, 16,  9, 15, 15, 10,  5, 14,  6,  3, 13,  0, 16,\n",
      "                            18, 18,  4,  5,  5,  8, 18, 16, 16, 14, 14, 16, 13,  7,  5,  7, 16,\n",
      "                            11, 19,  6,  9, 11])\n",
      "ic| self.pose.length(): 478\n",
      "ic| self.pose.binder_len(): 227\n",
      "ic| self.pose.L.seq: array([ 3,  9,  5, 12, 16,  5, 15, 14, 15, 15, 10, 15,  0, 15, 19,  7,  3,\n",
      "                             1, 19, 16,  9, 16,  4,  1,  0, 15,  5,  3, 19,  2, 16,  0, 19,  0,\n",
      "                            17, 18,  5,  5, 11, 14,  7, 11,  0, 14, 11, 10, 10,  9, 18, 15,  0,\n",
      "                            15, 13, 10, 18, 15,  7, 19, 14, 15,  1, 13, 15,  7, 15,  1, 15,  7,\n",
      "                            16,  3, 13, 16, 10, 16,  9, 15, 15, 10,  5, 14,  6,  3, 13,  0, 16,\n",
      "                            18, 18,  4,  5,  5,  8, 18, 16, 16, 14, 14, 16, 13,  7,  5,  7, 16,\n",
      "                            11, 19,  6,  9, 11])\n",
      "ic| f'Using {res} as a hotspot': \"Using ['T' '305'] as a hotspot\"\n",
      "ic| f'Using {res} as a hotspot': \"Using ['T' '456'] as a hotspot\"\n",
      "ic| self.ab_item.loop_mask: tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False,  True,  True,\n",
      "                                     True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With this beta schedule (linear schedule, beta_0 = 0.04, beta_T = 0.28), alpha_bar_T = 0.00013696050154976547\n",
      "Using cached chi_beta_T dictionary.\n",
      "Done calculating chi_beta_T, chi_alphas_T, and chi_abars_T dictionaries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ", False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False, False, False,\n",
      "                                    False, False, False, False, False, False, False, False])\n",
      "ic| self.ab_item.hotspots: tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, False, False, False, False, False,\n",
      "                                   False, False, False, False, False, IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_init, seq_init = sampler.sample_init() # this step is what we did in the Sampler section n last notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb01ea-637f-4204-b0cd-ef20517f9806",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "* Assume we satrt from step 50, the denoised to step 0\n",
    "* The following steps are how it inplemented\n",
    "* For the descriptons of each input features, plz refer to [Supplementary Methods Table2](https://www.biorxiv.org/content/10.1101/2024.03.14.585103v1.supplementary-material?versioned=true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8faf31ff-fdb0-42ec-935f-fb05855f13a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| f'Featurizing with {T_scheme}': 'Featurizing with single_T_correct_selfcond'\n"
     ]
    }
   ],
   "source": [
    "from rfantibody.rfdiffusion.inference.ab_util import featurize, process_init_selfcond, process_selfcond\n",
    "import numpy as np\n",
    "\n",
    "t = 50\n",
    "x_t, seq_t = x_init.clone(), seq_init.clone()\n",
    "\n",
    "L = x_t.shape[0] # get the total length\n",
    "tmp_xyz = torch.full((L, 27, 3), np.nan)\n",
    "tmp_xyz[:, :14] = x_t\n",
    "\n",
    "features = featurize(sampler.ab_item,\n",
    "                     seq_t,\n",
    "                     tmp_xyz,\n",
    "                     sampler.preprocess_conf.d_t1d,\n",
    "                     sampler.preprocess_conf.hotspot_dim,\n",
    "                     sampler.ab_conf.T_scheme,\n",
    "                     1 - (t / sampler.T),\n",
    "                     ~sampler.preprocess_conf.motif_sidechain_input,\n",
    "                     ~sampler.ab_conf.no_bugfix_t1d_mask)\n",
    "\n",
    "idx_pdb = torch.arange(L) \n",
    "if sampler.ab_item.target:\n",
    "    idx_pdb[sampler.ab_item.target_mask] += 200 # Do idx jump at chainbreak\n",
    "\n",
    "## Add hotspots to t1d ##\n",
    "#########################\n",
    "features['t1d'][...,22] = sampler.ab_item.hotspots[None,None]\n",
    "\n",
    "retval = (\n",
    "          features['msa_masked'],\n",
    "          features['msa_full'],\n",
    "          features['seq'],\n",
    "          features['xyz_prev'].unsqueeze(0),\n",
    "          idx_pdb.unsqueeze(0),\n",
    "          features['t1d'].unsqueeze(0),\n",
    "          features['t2d'].unsqueeze(0),\n",
    "          features['xyz_t'].unsqueeze(0),\n",
    "          features['alpha_t'].unsqueeze(0)\n",
    "         )\n",
    "\n",
    "# Send all inputs to device\n",
    "retval = [i.to(device) for i in retval]\n",
    "\n",
    "msa_masked, msa_full, seq_in, xt_in, idx_pdb, t1d, t2d, xyz_t, alpha_t = retval\n",
    "sc2d, xyz_sc = process_init_selfcond(t2d, xyz_t, sampler.ab_conf, xyz_t.device)\n",
    "\n",
    "msa_prev = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96668d5e-1e95-4b05-b540-7d02d1ff2902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'single_T_correct_selfcond'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.ab_conf['T_scheme']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59a95883-4180-465c-b10e-aaefdf883c10",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "* We've processed the features ready to the model, so let's check the architecture of the RosseTTAFold now\n",
    "* The RosseTTAFold is kinda straidforward, the model structure is as follows:\n",
    "  ![RF workflow](RFM.jpg)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc4a21d-9233-4725-bf3e-545ba1a63505",
   "metadata": {},
   "source": [
    "* You can call the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee1dbeca-d6fb-43b3-8d8a-1a2747e745bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rfantibody.rfdiffusion.RoseTTAFoldModel import RoseTTAFoldModule\n",
    "\n",
    "RosettaModel = RoseTTAFoldModule(**sampler._conf.model, \n",
    "                                 d_t1d=sampler.d_t1d, \n",
    "                                 d_t2d=sampler.d_t2d, \n",
    "                                 use_selfcond_emb=sampler.use_selfcond_emb, \n",
    "                                 T=sampler._conf.diffuser.T).to(device)\n",
    "\n",
    "RosettaModel.eval()\n",
    "\n",
    "test = RosettaModel(msa_masked[...,:10, :],\n",
    "                    msa_full[..., :10, :],\n",
    "                    seq_in[:, :10, :],\n",
    "                    xt_in[:, :10, ...],\n",
    "                    idx_pdb[:, :10],\n",
    "                    t1d=t1d[..., :10, :],\n",
    "                    t2d=t2d[..., :10, :10, :],\n",
    "                    sc2d=sc2d,\n",
    "                    xyz_sc=xyz_sc,\n",
    "                    xyz_t=xyz_t[..., :10, :, :],\n",
    "                    alpha_t=alpha_t[..., :10, :],\n",
    "                    msa_prev = msa_prev,\n",
    "                    pair_prev = None,\n",
    "                    state_prev = None,\n",
    "                    t=torch.tensor(t),\n",
    "                    return_infer=True,\n",
    "                    motif_mask=sampler.diffusion_mask[:10].squeeze().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2d78108-6573-4110-8c9a-544916a7f288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1ef34-0661-4fe2-8688-6afec245f10f",
   "metadata": {},
   "source": [
    "* Next, we'll go through each sub-module of the RosettaFold.\n",
    "# MSA embedding\n",
    "* We don't really need mutiple-sequence alignment here since we only have one masked sequence. I guess the authors wanted to align to the original RF model.\n",
    "* For the following sub-module, I'll show you the detailed inplementation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89eab6cf-ac17-43ec-ad21-f76864b90ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfantibody.rfdiffusion.Embeddings import MSA_emb\n",
    "\n",
    "d_msa = sampler._conf.model.d_msa\n",
    "d_pair = sampler._conf.model.d_pair\n",
    "d_state = 32\n",
    "p_drop = sampler._conf.model.p_drop\n",
    "input_seq_onehot = sampler._conf.model.input_seq_onehot\n",
    "\n",
    "latent_emb = MSA_emb(d_msa=d_msa, d_pair=d_pair, d_state=d_state,\n",
    "                p_drop=p_drop, input_seq_onehot=False).to(device)\n",
    "\n",
    "msa_latent, pair, state = latent_emb(msa_masked[...,:10, :],\n",
    "                                     seq_in[:, :10, :],\n",
    "                                     idx_pdb[:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7933ae2d-9e25-4537-8b2f-38c3076a9bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 10, 256]),\n",
       " torch.Size([1, 10, 10, 128]),\n",
       " torch.Size([1, 10, 32]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_latent.shape, pair.shape, state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34042948-58a3-4e69-aa60-199ff252905b",
   "metadata": {},
   "source": [
    "* As you can see above, the **latent_emb** module output three variables, the latent msa emb, pair emb and state repr.\n",
    "* In the original code, the author used a **one-hot trick** by Sergey. I kepting using the official API for simplicity.\n",
    "* The authors also provided some custome initialization methods, I also replace it with official API.\n",
    "* Next is how it implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70affb92-70e7-4f4e-a972-c2ac69a1063c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from rfantibody.rfdiffusion.Embeddings import PositionalEncoding2D\n",
    "\n",
    "class MSA_emb_revised(nn.Module):\n",
    "    def __init__(self, d_msa=256, \n",
    "                         d_pair=128,\n",
    "                        d_state=32,\n",
    "                        p_drop=0.1,\n",
    "                        input_seq_onehot=False,\n",
    "                        d_init=48,\n",
    "                        minpos=-32,\n",
    "                        maxpos=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Linear(d_init, d_msa)\n",
    "        self.seq_emb1 = nn.Linear(22, d_msa, bias=False)\n",
    "        init.kaiming_normal_(self.seq_emb1.weight, mode='fan_in', nonlinearity='linear')\n",
    "\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "\n",
    "        self.emb_left = nn.Linear(22, d_pair, bias=False)\n",
    "        self.emb_right = nn.Linear(22, d_pair, bias=False)\n",
    "        init.kaiming_normal_(self.emb_left.weight, mode='fan_in', nonlinearity='linear')\n",
    "        init.kaiming_normal_(self.emb_right.weight, mode='fan_in', nonlinearity='linear')\n",
    "        self.pos = PositionalEncoding2D(d_pair, minpos=minpos, maxpos=maxpos, p_drop=p_drop)\n",
    "\n",
    "        self.emb_state = nn.Linear(22, d_state, bias=False)\n",
    "        init.kaiming_normal_(self.emb_state.weight, mode='fan_in', nonlinearity='linear')\n",
    "        \n",
    "    def forward(self, msa, seq, idx):\n",
    "        \"\"\"\n",
    "        msa: [B, N, L, d_init]\n",
    "        seq: [B, L, 22]\n",
    "        idx: [B, L]\n",
    "        \"\"\"\n",
    "        N = msa.shape[1] # N represents the number of seqs in MSAs, here's always 1!\n",
    "        msa_latent = self.emb(msa) # [B, N, L, d_msa]\n",
    "        \n",
    "        tmp = self.seq_emb1(seq).unsqueeze(1) # [B, 1, L, d_msa]\n",
    "        msa_latent += tmp.expand(-1, N, -1, -1)\n",
    "        msa_latent = self.drop(msa_latent)\n",
    "        \n",
    "        left = self.emb_left(seq).unsqueeze(2)\n",
    "        right = self.emb_right(seq).unsqueeze(1)\n",
    "\n",
    "        pair = left + right\n",
    "        #print(left.shape, right.shape, pair.shape)\n",
    "        pair += self.pos(pair, idx)\n",
    "\n",
    "        state = self.drop(self.emb_state(seq))\n",
    "\n",
    "        return msa_latent, pair, state\n",
    "\n",
    "MSA_emb_revised\n",
    "latent_emb_revised = MSA_emb_revised(d_msa=d_msa, d_pair=d_pair, d_state=d_state,\n",
    "                p_drop=p_drop, input_seq_onehot=False).to(device)\n",
    "\n",
    "msa_latent_rv, pair_rv, state_rv = latent_emb_revised(msa_masked[...,:10, :],\n",
    "                                     seq_in[:, :10, :],\n",
    "                                     idx_pdb[:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29d9fe16-02da-4e5b-89f2-5395f7386035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 10, 256]),\n",
       " torch.Size([1, 10, 10, 128]),\n",
       " torch.Size([1, 10, 32]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_latent_rv.shape, pair_rv.shape, state_rv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d90369-5b54-4ddd-a116-e19c150706e1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "* As shown above, the output tensors have identical shapes. However, their actual values differ due to the distinct weight initialization methods we employed.\n",
    "\n",
    "* The denoised model retains the extra_msa module—referred to here as **full_emb**. Let’s now examine what this extra_msa (i.e., full_emb) module actually does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c5d584d-7884-478c-9beb-e98857f0b554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rfantibody.rfdiffusion.Embeddings import Extra_emb\n",
    "\n",
    "d_msa_full = sampler._conf.model.d_msa_full\n",
    "\n",
    "full_emb = Extra_emb(d_msa=d_msa_full, d_init=25,\n",
    "                p_drop=p_drop, input_seq_onehot=False).to(device)\n",
    "\n",
    "msa_full_ot = full_emb(msa_full[...,:10, :],\n",
    "                     seq_in[:, :10, :],\n",
    "                     idx_pdb[:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e9c9466-1843-40ed-8616-1cc8b6c0cb7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 64])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_full_ot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829caf7d-4c9e-41de-b2f1-3faf740d1c4a",
   "metadata": {},
   "source": [
    "* We’ll now implement Extra_emb step by step, just as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e5cbda5-708e-45a9-8068-bca5b0c7cddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 64])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Extra_emb_revised(nn.Module):\n",
    "    def __init__(self, d_msa=256,\n",
    "                        d_init=25,\n",
    "                        p_drop=0.1,\n",
    "                        input_seq_onehot=False):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Linear(d_init, d_msa)\n",
    "        self.emb_q = nn.Linear(22, d_msa, bias=False)\n",
    "        init.kaiming_normal_(self.emb_q.weight,  mode='fan_in', nonlinearity='linear')\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "        \n",
    "    def forward(self, msa, seq, idx):\n",
    "        \"\"\"\n",
    "        msa: [B, N, L, d_init]\n",
    "        seq: [B, L, 22]\n",
    "        idx: [B, L]\n",
    "        \"\"\"\n",
    "        N = msa.shape[1]\n",
    "        full_msa = self.emb(msa) # [B, N, L, d_msa]\n",
    "        seq = self.emb_q(seq).unsqueeze(1) # [B, 1, L, d_msa]\n",
    "\n",
    "        full_msa += seq.expand(-1, N, -1, -1) \n",
    "\n",
    "        return self.drop(full_msa)\n",
    "\n",
    "full_emb_rv = Extra_emb_revised(d_msa=d_msa_full, d_init=25,\n",
    "                p_drop=p_drop, input_seq_onehot=False).to(device)\n",
    "\n",
    "msa_full_ot_rv = full_emb(msa_full[...,:10, :],\n",
    "                     seq_in[:, :10, :],\n",
    "                     idx_pdb[:, :10])\n",
    "\n",
    "msa_full_ot_rv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb39ba-5a52-4df0-9794-b9c342729315",
   "metadata": {},
   "source": [
    "# RECYCLE Module\n",
    "* This module accepts previous iterations as input, information is passed through network iterations.\n",
    "* The initial **msa_prev**, **pair_prev** and **state_prev** can be set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47864671-697b-44d3-ae7c-3c9e1abca557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfantibody.rfdiffusion.Embeddings import Recycling\n",
    "import torch\n",
    "\n",
    "msa_prev = torch.zeros_like(msa_latent[:, 0])\n",
    "pair_prev = torch.zeros_like(pair)\n",
    "state_prev = torch.zeros_like(state)\n",
    "\n",
    "recycle = Recycling(d_msa=d_msa, d_pair=d_pair, d_state=d_state).to(device)\n",
    "msa_recycle, pair_recycle, state_recycle = recycle(seq_in[:, :10, :],\n",
    "                                                   msa_prev, \n",
    "                                                   pair_prev, \n",
    "                                                   xt_in[:, :10, ...], \n",
    "                                                   state_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2217429c-1181-4374-8f0e-a0d0936de369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rfantibody.rfdiffusion.util_module import rbf\n",
    "\n",
    "class Recycling_revised(nn.Module):\n",
    "    def __init__(self,d_msa=256, d_pair=128, d_state=32):\n",
    "        super().__init__()\n",
    "        self.proj_dist = nn.Linear(36+d_state*2, d_pair)\n",
    "        self.norm_state = nn.LayerNorm(d_state)\n",
    "        self.norm_pair = nn.LayerNorm(d_pair)\n",
    "        self.norm_msa = nn.LayerNorm(d_msa)\n",
    "\n",
    "        # reset parameters here\n",
    "    def forward(self, seq, msa, pair, xyz, state):\n",
    "        \"\"\"\n",
    "        seq: [B, L, 22]\n",
    "        msa: [B, N, L, d_init]\n",
    "        pair: [B, L, L, 128]\n",
    "        xyz: [B, L, 27, 3]\n",
    "        state: [B, L, 32]\n",
    "        \"\"\"\n",
    "        B, L = seq.shape[:2]\n",
    "        msa = self.norm_msa(msa)\n",
    "        state = self.norm_state(state)\n",
    "\n",
    "        left = state.unsqueeze(2).expand(-1, -1, L, -1) # [B, L, L, 64]\n",
    "        right = state.unsqueeze(1).expand(-1, L, -1, -1)\n",
    "\n",
    "        Nitro = xyz[:, :, 0, :] # [B, L, 3]\n",
    "        CA = xyz[:, :, 1, :]\n",
    "        C = xyz[:, :, 2, :]\n",
    "\n",
    "        b = CA - Nitro\n",
    "        c = C -CA\n",
    "        a = torch.cross(b, c, dim=-1) # orthogonal vector\n",
    "        CB = -0.58273431*a + 0.56802827*b - 0.54067466*c + CA\n",
    "\n",
    "        dist = rbf(torch.cdist(CB, CB)) # [B, L, L, 36]\n",
    "        #print(dist.shape, left.shape, right.shape)\n",
    "        dist = torch.cat([dist, left, right], dim=-1) # [B, L, L, 36+64*2]\n",
    "        dist = self.proj_dist(dist)\n",
    "\n",
    "        pair = dist + self.norm_pair(pair)\n",
    "\n",
    "        return msa, pair, dist\n",
    "\n",
    "recycle_rv = Recycling_revised(d_msa=d_msa, d_pair=d_pair, d_state=d_state).to(device)\n",
    "msa_recycle2, pair_recycle2, state_recycle2 = recycle_rv(seq_in[:, :10, :],\n",
    "                                                   msa_prev, \n",
    "                                                   pair_prev, \n",
    "                                                   xt_in[:, :10, ...], \n",
    "                                                   state_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b67f6b8-d5a7-470a-8304-53a5496feb14",
   "metadata": {},
   "source": [
    "* The authors used a residue-style logic to update msa, pair and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3074742f-47b8-4208-bcfc-fd453e3fece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#msa_latent.shape, msa_recycle.shape\n",
    "msa_latent[:, 0, ...] = msa_latent[:, 0, ...] + msa_recycle\n",
    "pair += pair_recycle\n",
    "state += state_recycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae6bbe1-c215-48f9-9a9c-242026868587",
   "metadata": {},
   "source": [
    "# Timestep Embedding\n",
    "* timestep embedding is disabled in the example, but you can take a look how it works here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "97d30053-e48e-4efd-97b6-03a9d2f8ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfantibody.rfdiffusion.Embeddings import Timestep_emb\n",
    "\n",
    "# set l=10 \n",
    "timestep_embedder = Timestep_emb(input_size=8, \n",
    "                              output_size=sampler._conf.model.d_time_emb_proj,\n",
    "                              T=50,\n",
    "                              use_motif_timestep=sampler._conf.model.use_motif_timestep).to(device)\n",
    "\n",
    "time_emb = timestep_embedder(10,\n",
    "                             torch.tensor(t),\n",
    "                             sampler.diffusion_mask[:10].squeeze().to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3142d1-2a72-4c24-89b1-7265b309d312",
   "metadata": {},
   "source": [
    "# Template Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1c6a05c5-e642-4447-99d4-6c8323fabf58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rfantibody.rfdiffusion.Embeddings import Templ_emb\n",
    "\n",
    "d_templ = sampler._conf.model.d_templ\n",
    "n_head_templ = sampler._conf.model.n_head_templ\n",
    "d_hidden_templ = sampler._conf.model.d_hidden_templ\n",
    "d_t1d, d_t2d = sampler.d_t1d, sampler.d_t2d\n",
    "\n",
    "templ_emb = Templ_emb(d_pair=d_pair, d_templ=d_templ, d_state=d_state,\n",
    "                                   n_head=n_head_templ,\n",
    "                                   d_hidden=d_hidden_templ, p_drop=0.25, d_t1d=d_t1d, d_t2d=d_t2d).to(device)\n",
    "\n",
    "pair_wt, state_wt = templ_emb(t1d[..., :10, :],\n",
    "                                     t2d[..., :10, :10, :],\n",
    "                                     alpha_t[..., :10, :], \n",
    "                                     xyz_t[..., :10, :, :],\n",
    "                                     pair, \n",
    "                                     state, \n",
    "                                     use_checkpoint=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f88398-c530-44f5-932d-6c460adbd4b4",
   "metadata": {},
   "source": [
    "* The template module consists of several key sub-modules, including **PairStr2Pair** and **Attention** modules, the workflow proceeds as ![follows](./templ.png):\n",
    "* I'll go through the two key components step by step\n",
    "  * In the original code, the authors named it as **templ_stack**, which is **TemplatePairStack** consists of multiple Pair2StrPair layers. So lets take a look what a single Pair2StrPair performs:\n",
    "        * This layers consists of two ** BiasedAxialAttention** layer but focus on differnent dim called row_attn and col_attn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "29e7443d-164c-4860-8c1d-efc1f47df4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfantibody.rfdiffusion.util_module import rbf\n",
    "\n",
    "test_t1d, test_t2d, test_alphat, test_coords, test_pair, test_state = t1d[..., :10, :], \\\n",
    "                                                                     t2d[..., :10, :10, :],\\\n",
    "                                                                     alpha_t[..., :10, :], \\\n",
    "                                                                     xyz_t[..., :10, :, :],\\\n",
    "                                                                     pair, \\\n",
    "                                                                     state\n",
    "\n",
    "B, T, L, _ = test_t1d.shape\n",
    "\n",
    "# Prepare 2D template features\n",
    "left = test_t1d.unsqueeze(3).expand(-1,-1,-1,L,-1)\n",
    "right = test_t1d.unsqueeze(2).expand(-1,-1,L,-1,-1)\n",
    "#\n",
    "templ = torch.cat((test_t2d, left, right), -1) # (B, T, L, L, 90)\n",
    "\n",
    "emb = nn.Linear(d_t1d*2+d_t2d, d_templ).to(device)\n",
    "templ = emb(templ).reshape(B*T, L, L, -1) # Template templures (B, T, L, L, d_templ)\n",
    "# process each template features\n",
    "test_coords = test_coords.reshape(B*T, L, -1, 3)\n",
    "rbf_feat = rbf(torch.cdist(test_coords[:,:,1], test_coords[:,:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611373a3-a6cd-44b9-904c-724aade62399",
   "metadata": {},
   "source": [
    "* Now we already have the inputs for PairStr2Pair module. Let's see how AxialaAttention work here\n",
    "* I'll show the row_attention next:\n",
    "  $out = softmax(Q*K^T/sqrt(L) + bias) * V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d46b419e-d61b-40df-9386-33384712323a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BiasedAxialAttention_mannual(nn.Module):\n",
    "    def __init__(self, d_pair, d_bias, n_head, d_hidden, p_drop=0.1, is_row=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.is_row = is_row\n",
    "        self.norm_pair = nn.LayerNorm(d_pair)\n",
    "        self.norm_bias = nn.LayerNorm(d_bias)\n",
    "        \n",
    "        self.Q = nn.Linear(d_pair, n_head*d_hidden, bias=False)\n",
    "        self.K = nn.Linear(d_pair, n_head*d_hidden, bias=False)\n",
    "        self.V = nn.Linear(d_pair, n_head*d_hidden, bias=False)\n",
    "\n",
    "        self.b = nn.Linear(d_bias, n_head, bias=False)\n",
    "        self.to_g = nn.Linear(d_pair, n_head*d_hidden)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.to_out = nn.Linear(n_head*d_hidden, d_pair)\n",
    "        \n",
    "        self.n_head, self.d_hidden = n_head, d_hidden\n",
    "        \n",
    "        # self.reser_parameter()\n",
    "        # skip parameter initialization here\n",
    "        # it should be initialized properly\n",
    "    def reset_parameter(self):\n",
    "        nn.init.xavier_uniform_()\n",
    "        \n",
    "    def forward(self, templ, rbf_feat):\n",
    "        \"\"\"\n",
    "        templ: [B, L, L, d_pair] as qkv\n",
    "        rbf: [B, L, L, d_rbf]\n",
    "\n",
    "        Q,K,V come from templ\n",
    "        using rbf feat as bias to update\n",
    "        \"\"\"\n",
    "        B, L = templ.shape[:2]\n",
    "\n",
    "        if self.is_row:\n",
    "            templ = templ.permute(0,2,1,3)\n",
    "            rbf_feat = rbf_feat.permute(0,2,1,3)\n",
    "\n",
    "        Q = self.Q(templ).reshape(B, L, L, self.n_head, self.d_hidden) # [B, L, L, h, d]\n",
    "        K = self.K(templ).reshape(B, L, L, self.n_head, self.d_hidden)\n",
    "        V = self.V(templ).reshape(B, L, L, self.n_head, self.d_hidden)\n",
    "\n",
    "        bias = self.b(rbf_feat) # [B, L, L, h]\n",
    "        gate = self.sigmoid(self.to_g(templ)) # [B, L, L, h*d]\n",
    "        \n",
    "        attn = torch.einsum(\"bnihd,bnjhd->bijh\", Q, K) / math.sqrt(L) # [B, L, L, h]\n",
    "        attn += bias\n",
    "        attn = nn.functional.softmax(attn, dim=-1)\n",
    "\n",
    "        out = torch.einsum(\"bijh,bkjhd->bikhd\", attn, V).reshape(B, L, L, self.n_head * self.d_hidden) # [B, L, L, h*d]\n",
    "        out *= gate\n",
    "        \n",
    "        out = self.to_out(out) # [B, L, L, d_pair)\n",
    "\n",
    "        if self.is_row:\n",
    "            out = out.permute(0,2,1,3)\n",
    "\n",
    "        return out\n",
    "\n",
    "row_attn = BiasedAxialAttention_mannual(64, 36, n_head=4, d_hidden=32, p_drop=p_drop, is_row=True).to(device)\n",
    "out = row_attn(templ, rbf_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e423b3-e0f7-464d-af95-c54f884f228f",
   "metadata": {},
   "source": [
    "* Unlike standard attention, which computes interactions between all pairs of tokens, axial attention operates separately along rows or columns.\n",
    "Moreover, instead of deriving the bias from pairwise features as in AlphaFold 3 (AF3), the authors introduce a distinct bias term.\n",
    "* Row-wise attention indicates which other residues residue i attends to (i.e., which residues are relevant to i).\n",
    "* Column-wise attention captures which other residues influence residue j (i.e., which residues provide context for j).\n",
    "* As evidenced by the operation `torch.einsum(\"bnihd,bnjhd->bijh\", Q, K)`, the attention is computed between the i-th and j-th columns, making the mechanism inherently column-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c370d6e-0fa5-49a5-a89e-735071600153",
   "metadata": {},
   "source": [
    "* Next is the most important module -- **IterativeSimulator**, which consists of several iter blocks\n",
    "* To ensure dimensional consistency, I applied the following dimensionality transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "067d51d7-6760-4c56-9fc0-c3fbb153a084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rfantibody.rfdiffusion.Track_module import IterativeSimulator\n",
    "\n",
    "# initilizate the parameters\n",
    "n_extra_block = sampler._conf.model.n_extra_block\n",
    "n_main_block = sampler._conf.model.n_main_block\n",
    "n_ref_block = sampler._conf.model.n_ref_block\n",
    "n_head_msa = sampler._conf.model.n_head_msa\n",
    "n_head_pair = sampler._conf.model.n_head_pair\n",
    "d_hidden = sampler._conf.model.d_hidden\n",
    "SE3_param_full = sampler._conf.model.SE3_param_full\n",
    "SE3_param_topk = sampler._conf.model.SE3_param_topk\n",
    "\n",
    "motif_mask=sampler.diffusion_mask[:10].squeeze().to(device)\n",
    "\n",
    "simulator = IterativeSimulator(n_extra_block=n_extra_block,\n",
    "                                            n_main_block=n_main_block,\n",
    "                                            n_ref_block=n_ref_block,\n",
    "                                            d_msa=d_msa, d_msa_full=d_msa_full,\n",
    "                                            d_pair=d_pair, d_hidden=d_hidden,\n",
    "                                            n_head_msa=n_head_msa,\n",
    "                                            n_head_pair=n_head_pair,\n",
    "                                            SE3_param_full=SE3_param_full,\n",
    "                                            SE3_param_topk=SE3_param_topk,\n",
    "                                            p_drop=p_drop).to(device)\n",
    "\n",
    "\n",
    "\n",
    "msa_update, pair_update, R, T, alpha_s, state_update = simulator(seq_in[:, :10, :], \n",
    "                                                                 msa_latent, \n",
    "                                                                 msa_full_ot, \n",
    "                                                                 pair, \n",
    "                                                                 xt_in[:, :10, :3],\n",
    "                                                                 state.repeat(1, 1, 2), \n",
    "                                                                 idx_pdb[:, :10], \n",
    "                                                                 use_checkpoint=False,\n",
    "                                                                 motif_mask=motif_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea61a6-8059-46e0-a74d-a0bf15b9218a",
   "metadata": {},
   "source": [
    "* The *IterativeSimulator* consists of 3 sub-modules: extra_block, main_block and ref_block. The first two sub-modules are based on **IterBlock**.\n",
    "* Each IterBlock includs 4 types of modules, which are **MSAPairStr2MSA**, **MSA2Pair**, **PairStr2Pair** and **Str2Str**, we'll go through the details of theses modules step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a08f982a-ac91-41ce-b5d1-141319a8fca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MSAPaieStr2MSA\n",
    "from rfantibody.rfdiffusion.Track_module import MSAPairStr2MSA\n",
    "\n",
    "msa2msa = MSAPairStr2MSA(d_msa=d_msa_full, \n",
    "                         d_pair=d_pair,\n",
    "                          n_head=n_head_msa,\n",
    "                          d_state=64, #SE3_param['l0_out_features'],\n",
    "                          use_global_attn=True,\n",
    "                          d_hidden=32, \n",
    "                          p_drop=p_drop).to(device)\n",
    "\n",
    "xyz = xt_in[:, :10, :3]\n",
    "rbf_feat = rbf(torch.cdist(xyz[:,:,1,:], xyz[:,:,1,:])) \n",
    "msa_ = msa2msa(msa_full_ot, \n",
    "        pair, \n",
    "        rbf_feat, \n",
    "        state_update) # [1, 1, 10, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "dbd1a629-e126-42d5-8dd1-27bf084b26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfantibody.rfdiffusion.Attention_module import SequenceWeight\n",
    "\n",
    "class MSARowAttentionWithBias_mannual(nn.Module):\n",
    "    def __init__(self, d_msa=64,\n",
    "                        d_pair=128,\n",
    "                        n_head=8, \n",
    "                        d_hidden=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm_msa = nn.LayerNorm(d_msa)\n",
    "        self.norm_pair = nn.LayerNorm(d_pair)\n",
    "\n",
    "        self.seq_weight = SequenceWeight(d_msa, n_head, d_hidden, p_drop=0.1)\n",
    "        self.Q = nn.Linear(d_msa, n_head*d_hidden, bias=False)\n",
    "        self.K = nn.Linear(d_msa, n_head*d_hidden, bias=False)\n",
    "        self.V = nn.Linear(d_msa, n_head*d_hidden, bias=False)\n",
    "\n",
    "        self.B = nn.Linear(d_pair, n_head, bias=False)\n",
    "        self.G = nn.Linear(d_msa, n_head*d_hidden)\n",
    "        self.out = nn.Linear(n_head*d_hidden, d_msa)\n",
    "\n",
    "        self.h, self.dim = n_head, d_hidden\n",
    "\n",
    "        #reset parameter\n",
    "        \n",
    "    def forward(self, msa, pair):\n",
    "        \"\"\"\n",
    "        - msa: MSA feature (B, N, L, d_msa)\n",
    "        - pair: Pair feature (B, L, L, d_pair)\n",
    "        \"\"\"\n",
    "        B, N, L = msa.shape[:3]\n",
    "        msa = self.norm_msa(msa)\n",
    "        pair = self.norm_pair(pair)\n",
    "\n",
    "        seq_weight = self.seq_weight(msa) # [B, N, L, h, 1]\n",
    "        \n",
    "        q = self.Q(msa).reshape(B, N, L, self.h, self.dim) # [B, N, L, h, d]\n",
    "        k = self.K(msa).reshape(B, N, L, self.h, self.dim)\n",
    "        v = self.V(msa).reshape(B, N, L, self.h, self.dim)\n",
    "\n",
    "        bias = self.B(pair) # [B, L, L, h]\n",
    "        gate = torch.sigmoid(self.G(msa))\n",
    "        q *= seq_weight.expand(-1, -1, -1, -1, self.dim)\n",
    "        attn = 1/math.sqrt(self.dim) * torch.einsum(\"bnqhd,bnkhd->bqkh\", q, k)#.reshape(B, L, L, -1)\n",
    "        attn = nn.functional.softmax(attn + bias, dim=-2) # (B, L, L, h)\n",
    "        out = torch.einsum(\"bqkh, bnkhd->bnqhd\", attn, v).reshape(B, N, L, -1)\n",
    "        out *= gate\n",
    "        out = self.out(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "\n",
    "class MSAColGlobalAttention_mannual(nn.Module):\n",
    "    def __init__(self,d_msa=64, \n",
    "                        n_head=8, \n",
    "                        d_hidden=8):\n",
    "        super().__init__()\n",
    "        self.Q = nn.Linear(d_msa, n_head*d_hidden, bias=False)\n",
    "        self.K = nn.Linear(d_msa, d_hidden, bias=False)\n",
    "        self.V = nn.Linear(d_msa, d_hidden, bias=False)\n",
    "\n",
    "        self.B = nn.Linear(d_pair, n_head, bias=False)\n",
    "        self.G = nn.Linear(d_msa, n_head*d_hidden)\n",
    "        self.out = nn.Linear(n_head*d_hidden, d_msa)\n",
    "\n",
    "        self.h, self.dim = n_head, d_hidden\n",
    "        #reset parameters\n",
    "        \n",
    "    def forward(self, msa):\n",
    "        # msa: [B, N, L, d_msa]\n",
    "        B, N, L = msa.shape[:3]\n",
    "        q = self.Q(msa).reshape(B, N, L, self.h, -1) # [B, N, L, h, d]\n",
    "        q = q.mean(dim=1) # [B, L, h, d]\n",
    "        k = self.K(msa).reshape(B, N, L, -1) # [B, N, L, d]\n",
    "        v = self.V(msa).reshape(B, N, L, -1)\n",
    "\n",
    "        attn = torch.einsum(\"bihd, bkid->bihk\", q, v) * 1/math.sqrt(self.dim)\n",
    "        attn = nn.functional.softmax(attn, dim=-1)\n",
    "        gate = torch.sigmoid(self.G(msa)) # [B, L, h, N]\n",
    "\n",
    "        out = torch.einsum(\"bihk,bkid->bihd\", attn, v).reshape(B, 1, L, -1)\n",
    "        out *= gate\n",
    "        out = self.out(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "class MSAColAttention_mannual(nn.Module):\n",
    "    def __init__(self,d_msa=64, \n",
    "                        n_head=8, \n",
    "                        d_hidden=8):\n",
    "        super().__init__()\n",
    "        self.Q = nn.Linear(d_msa, n_head*d_hidden, bias=False)\n",
    "        self.K = nn.Linear(d_msa, n_head*d_hidden, bias=False)\n",
    "        self.V = nn.Linear(d_msa, n_head*d_hidden, bias=False)\n",
    "\n",
    "        self.B = nn.Linear(d_pair, n_head, bias=False)\n",
    "        self.G = nn.Linear(d_msa, n_head*d_hidden)\n",
    "        self.out = nn.Linear(n_head*d_hidden, d_msa)\n",
    "\n",
    "        self.h, self.dim = n_head, d_hidden\n",
    "        #reset parameters\n",
    "        \n",
    "    def forward(self, msa):\n",
    "        # msa: [B, N, L, d_msa]\n",
    "        B, N, L = msa.shape[:3]\n",
    "        q = self.Q(msa).reshape(B, N, L, self.h, -1) # [B, N, L, h, d]\n",
    "        k = self.K(msa).reshape(B, N, L, self.h, -1) \n",
    "        v = self.V(msa).reshape(B, N, L, self.h, -1) \n",
    "\n",
    "        attn = torch.einsum(\"bqihd, bkihd->bihqk\", q, v) * 1/math.sqrt(self.d_hidden)\n",
    "        attn = nn.functional.softmax(attn, dim=-1)\n",
    "        gate = torch.sigmoid(self.G(msa)) # [B, N, L, h, d]\n",
    "\n",
    "        out = torch.einsum(\"bihqk,bkihd->bqihd\", attn, v).reshape(B, N, L, -1)\n",
    "        out *= gate\n",
    "        out = self.out(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3910a67-0f49-4f5f-a4be-9b999355497e",
   "metadata": {},
   "source": [
    "* In this **GlobalAttention** mechanism, each query—indexed by batch, position, and head as [B,L,h] —is attended to by all N sequences in the MSA. Specifically, the query at position i interacts with keys from all sequences at the same position, producing attention scores of shape [B,L,h,N] . These scores are then used to compute a weighted sum over the corresponding values [B,N,L,h,d] , aggregating information across the N sequences for each position and head. The result is a context-enhanced representation of shape [B,L,h,d] , which is expanded to [B,1,L,h⋅d] and broadcast only to the first row of the MSA (i.e., the target sequence)\n",
    "* In line 53 below. This ensures that the global MSA context is injected solely into the primary sequence, while other sequences remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b04ee5d8-c069-4e95-ab24-bb27f57c9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSAPairStr2MSA \n",
    "# state -> msa -> row_attn -> col_attn -> msa\n",
    "from rfantibody.rfdiffusion.Attention_module import FeedForwardLayer\n",
    "from rfantibody.rfdiffusion.util_module import Dropout\n",
    "\n",
    "class MSAPairStr2MSA_mannual(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_msa=64, \n",
    "                 d_pair=128, \n",
    "                 n_head=8, \n",
    "                 d_state=64,\n",
    "                 d_hidden=32, \n",
    "                 p_drop=0.15, \n",
    "                 use_global_attn=True):\n",
    "        super().__init__()\n",
    "        self.norm_pair = nn.LayerNorm(d_pair)\n",
    "        self.proj_pair = nn.Linear(d_pair+36, d_pair)\n",
    "        self.norm_state = nn.LayerNorm(d_state)\n",
    "        self.proj_state = nn.Linear(d_state, d_msa)\n",
    "\n",
    "        self.dropout_row = Dropout(broadcast_dim=1, p_drop=p_drop)\n",
    "\n",
    "        self.row_attn = MSARowAttentionWithBias_mannual(d_msa=d_msa, \n",
    "                                                d_pair=d_pair, \n",
    "                                                n_head=n_head, \n",
    "                                                d_hidden=d_hidden)\n",
    "        if use_global_attn:\n",
    "            self.col_attn = MSAColGlobalAttention_mannual(d_msa=d_msa, n_head=n_head, d_hidden=d_hidden) \n",
    "        else:\n",
    "            self.col_attn = MSAColAttention_mannual(d_msa=d_msa, n_head=n_head, d_hidden=d_hidden) \n",
    "        self.ff = FeedForwardLayer(d_msa, 4, p_drop=p_drop)\n",
    "\n",
    "        # self.reset_paramter()\n",
    "    def forward(self, msa, pair, rbf_feat, state):\n",
    "        '''\n",
    "        Inputs:\n",
    "            - msa: MSA feature (B, N, L, d_msa)\n",
    "            - pair: Pair feature (B, L, L, d_pair)\n",
    "            - rbf_feat: Ca-Ca distance feature calculated from xyz coordinates (B, L, L, 36)\n",
    "            - xyz: xyz coordinates (B, L, n_atom, 3)\n",
    "            - state: updated node features after SE(3)-Transformer layer (B, L, d_state)\n",
    "        Output:\n",
    "            - msa: Updated MSA feature (B, N, L, d_msa)\n",
    "        '''\n",
    "\n",
    "        B, N, L = msa.shape[:3]\n",
    "        pair = self.norm_pair(pair)\n",
    "        pair = torch.cat([pair, rbf_feat], axis=-1) # [B, L, L, d_pair+36]\n",
    "        pair = self.proj_pair(pair) \n",
    "\n",
    "        state = self.norm_state(state)\n",
    "        state = self.proj_state(state).unsqueeze(1)\n",
    "\n",
    "        msa.index_add_(1, torch.tensor([0,], device=state.device), state) # only add state to the very first row of MSA\n",
    "        msa += self.dropout_row(self.row_attn(msa, pair))\n",
    "        msa += self.col_attn(msa)\n",
    "        msa += self.ff(msa)\n",
    "\n",
    "        return msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "171332f6-f5dc-4c7e-a740-b69173e89d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msa2msa_m = MSAPairStr2MSA_mannual(d_msa=d_msa_full, \n",
    "                         d_pair=d_pair,\n",
    "                          n_head=n_head_msa,\n",
    "                          d_state=64, #SE3_param['l0_out_features'],\n",
    "                          use_global_attn=True,\n",
    "                          d_hidden=32, \n",
    "                          p_drop=p_drop).to(device)\n",
    "\n",
    "\n",
    "msa_m = msa2msa_m(msa_full_ot, \n",
    "        pair, \n",
    "        rbf_feat, \n",
    "        state_update) # [1, 1, 10, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "3efe4bef-c7f6-4658-a920-913a09cc7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then followed by MSA2Pair Module\n",
    "\n",
    "from rfantibody.rfdiffusion.Track_module import MSA2Pair\n",
    "\n",
    "msa2pair = MSA2Pair(d_msa=d_msa_full, d_pair=d_pair,\n",
    "                                 d_hidden=d_hidden//2, p_drop=p_drop).to(device)\n",
    "\n",
    "pair = msa2pair(msa_, pair) # [1, 10, 10, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685dc7de-a15f-4798-9bf9-546591d0bdc1",
   "metadata": {},
   "source": [
    "* Let's explain how MSA2Pair module work!\n",
    "* The input for this module are pair information and msa infos, we firstly transform the msa to match the shape of pair then add to pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "f08bc76f-2418-4c2b-9c4a-dc0795b6e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MSA2Pair_mannual(nn.Module):\n",
    "    def __init__(self, d_msa=64, \n",
    "                         d_pair=128,\n",
    "                         d_hidden=d_hidden//2, \n",
    "                         p_drop=p_drop):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.msa_norm = nn.LayerNorm(d_msa)\n",
    "        self.msa_left = nn.Linear(d_msa, d_hidden)\n",
    "        self.msa_right = nn.Linear(d_msa, d_hidden)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_hidden*d_hidden, d_pair)\n",
    "\n",
    "        # reset parameters\n",
    "    def forward(self, msa, pair):\n",
    "        \"\"\"\n",
    "        msa: [B, N, L, d_msa]\n",
    "        pair: [B, L, L, d_pair]\n",
    "        \"\"\"\n",
    "        B, N, L = msa.shape[:3]\n",
    "\n",
    "        msa = self.msa_norm(msa)\n",
    "        left = self.msa_left(msa) # [B, N, L, d_hidden]\n",
    "        right = self.msa_right(msa) / float(N)\n",
    "        #print(left.shape)\n",
    "        out = torch.einsum(\"bnik,bnjl->bijkl\", left, right).reshape(B, L, L, -1) # [B, L, L, d*d]\n",
    "        pair += self.out_proj(out)\n",
    "\n",
    "        return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5b831be5-800b-49ae-8cd5-ebce49e3be09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 10, 128])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa2pair_m = MSA2Pair_mannual(d_msa=d_msa_full, d_pair=d_pair,\n",
    "                                 d_hidden=d_hidden//2, p_drop=p_drop).to(device)\n",
    "\n",
    "msa2pair_m(msa_, pair).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b791fb-4fb9-4e98-90ba-fecdc0bdb8d5",
   "metadata": {},
   "source": [
    "* After updating msa and pair, then BiasedAxialAttention is inplemented twice for row and column axis to update the pair infos.\n",
    "* The BiasedAxialAttention is inplemented as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b6a19b6f-5d82-4e57-953d-12ad6d52df2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 10, 128])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rfantibody.rfdiffusion.Track_module import PairStr2Pair\n",
    "\n",
    "pair2pair = PairStr2Pair(d_pair=d_pair, n_head=n_head_pair, \n",
    "                                      d_hidden=d_hidden, p_drop=p_drop).to(device)\n",
    "\n",
    "pair = pair2pair(pair, rbf_feat)\n",
    "pair.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf164e-dae9-4ad6-94e5-932847de2528",
   "metadata": {},
   "source": [
    "* Then comes to the key component -- **Str2Str**, which outputs the rotation matrix **R** and translation vector **T**. Then one can update the noised coordinates by $R*x + T$.\n",
    "* SE(3)-transformer is applied to update the crds here: we need to construct a graph based on Ca crds, and pass it to se3 layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "5491a12f-6331-4ef9-9556-a15d01e2cda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 3, 3]),\n",
       " torch.Size([1, 10, 3]),\n",
       " torch.Size([1, 10, 8]),\n",
       " torch.Size([1, 10, 10, 2]))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rfantibody.rfdiffusion.Track_module import Str2Str\n",
    "\n",
    "#SE3_param={'l0_in_features':32, \n",
    "#           'l0_out_features':16, \n",
    "#           'num_edge_features':32}\n",
    "\n",
    "str2str = Str2Str(d_msa=d_msa_full, \n",
    "                  d_pair=d_pair,\n",
    "                   d_state=8,\n",
    "                   SE3_param=SE3_param_full,\n",
    "                   p_drop=p_drop).to(device)\n",
    "\n",
    "R_in = torch.eye(3, device=xyz.device).reshape(1,1,3,3).expand(1, 10, -1, -1)\n",
    "T_in = xyz[:,:,1].clone()\n",
    "\n",
    "R, T, state, alpha = str2str(msa_, pair, R_in, T_in, xyz, state, idx_pdb[:, :10], motif_mask=motif_mask, top_k=0) \n",
    "R.shape, T.shape, state.shape, alpha.shape     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "836d027a-b6b5-4a47-b205-25a9f2b7cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfantibody.rfdiffusion.Track_module import SCPred\n",
    "from rfantibody.rfdiffusion.SE3_network import SE3TransformerWrapper\n",
    "from rfantibody.rfdiffusion.util_module import rbf, make_full_graph, make_topk_graph\n",
    "\n",
    "class Str2Str_mannual(nn.Module):\n",
    "    def __init__(self, \n",
    "                  d_msa=64, \n",
    "                  d_pair=128,\n",
    "                   d_state=8,\n",
    "                   SE3_param={'l0_in_features':32, 'l0_out_features':16, 'num_edge_features':32},\n",
    "                   p_drop=.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.msa_norm = nn.LayerNorm(d_msa)\n",
    "        self.pair_norm = nn.LayerNorm(d_pair)\n",
    "        self.state_norm = nn.LayerNorm(d_state)\n",
    "\n",
    "        self.embed_x = nn.Linear(d_msa+d_state, SE3_param['l0_in_features'])\n",
    "        self.embed_e1 = nn.Linear(d_pair, SE3_param['num_edge_features'])\n",
    "        self.embed_e2 = nn.Linear(SE3_param['num_edge_features']+36+1, SE3_param['num_edge_features'])\n",
    "        \n",
    "        self.norm_node = nn.LayerNorm(SE3_param['l0_in_features'])\n",
    "        self.norm_edge1 = nn.LayerNorm(SE3_param['num_edge_features'])\n",
    "        self.norm_edge2 = nn.LayerNorm(SE3_param['num_edge_features'])\n",
    "\n",
    "        self.se3 = SE3TransformerWrapper(**SE3_param)\n",
    "        self.sc_predictor = SCPred(d_msa=d_msa, d_state=SE3_param['l0_out_features'],\n",
    "                                   p_drop=p_drop)\n",
    "\n",
    "        # reset parameters\n",
    "\n",
    "    def get_seqsep(self, idx):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, msa, pair, R_in, T_in, xyz, state, idx, motif_mask=motif_mask, top_k=0):\n",
    "        B, N, L = msa.shape[:3]\n",
    "\n",
    "        node = self.msa_norm(msa[:, 0, ...]) # norm the 1st seq itself\n",
    "        pair = self.pair_norm(pair) # [B, L, L, d_pair]\n",
    "        state = self.state_norm(state)\n",
    "\n",
    "        node = torch.cat([node, state], axis=-1) # [B, L, d_msa+d_state]\n",
    "        node = self.norm_node(self.embed_x(node)) # (B, L, x)\n",
    "        pair = self.norm_edge1(self.embed_e1(pair)) # (B, L, L, x)\n",
    "\n",
    "        neighbour = self.get_seqsep(idx) # actualy I didnot get what the authors wanna do here!\n",
    "        rbf_feat = rbf(torch.dist(xyz[:, :, 1, :], xyz[..., 1, :])) # Ca dist [B, L, L, 36]\n",
    "        pair = self.norm_edge2(\n",
    "                                self.embed_e2(\n",
    "                                    torch.cat([pair, rbf_feat, neighbour], axis=-1)\n",
    "                                            )\n",
    "                                )\n",
    "\n",
    "        if top_k == 0: # full graph\n",
    "            G, edge_feats = make_full_graph(xyz[..., 1, :], apir, idx, top_k=top_k)\n",
    "        else: # top-k nearest neighbours\n",
    "            G, edge_feats = make_topk_graph(xyz[..., 1, :], apir, idx, top_k=top_k)\n",
    "            \n",
    "        \n",
    "        l1_feats = xyz - xyz[..., 1, :].unsqueeze(2) # abs dist from Ca\n",
    "        l1_feats = l1_feats.reshape(B*L, -1, 3) # [B*L, 3, 3]\n",
    "\n",
    "        shift = self.se3(G, node.reshape(B*L, -1, 1), l1_feats, edge_feats) # a dict with keys ['0', '1']\n",
    "        state = shift['0'].reshape(B, L, -1) \n",
    "        offset = shift['1'].reshape(B, L, 2, 3)\n",
    "        offset[:, motif_mask, ...] = 0\n",
    "\n",
    "        delTi = offset[..., 0, :]/10.\n",
    "        R = offset[..., 1, :]/100.\n",
    "        Qnorm = torch.sqrt(1 + torch.sum(R*R, dim=-1)) # quaternion normalization factor\n",
    "        qA, qB, qC, qD = 1/Qnorm, R[:,:,0]/Qnorm, R[:,:,1]/Qnorm, R[:,:,2]/Qnorm # unit quaternion (qA, [qB, qC, qD])\n",
    "\n",
    "        delRi = torch.zeros([B, L, 3, 3], device=xyz.device)\n",
    "        \"\"\"\n",
    "        exp_R = [\n",
    "                [a**2+b**2-c**2-d**2, 2*b*c-2*a*d, 2*b*d+2*a*c],\n",
    "                [2*b*c+2*a*d, a**2-b**2+c**2-d**2, 2*c*d-2*a*b],\n",
    "                [2*b*d-2*a*c, 2*c*d+2*a*b, a**2-b**2-c**2+d**2]\n",
    "                ]\n",
    "        \"\"\"\n",
    "        delRi[..., 0, 0] = qA**2 + qB**2 - qC**2 - qD**2\n",
    "        delRi[..., 0, 1] = 2*qB*qC\n",
    "        delRi[..., 0, 2] = 2*qB*qD + 2*qA*qC\n",
    "        delRi[..., 1, 0] = 2*qB*qC + 2*qA*qD\n",
    "        delRi[..., 1, 1] = qA**2 - qB**2 + qC**2-qD**2\n",
    "        delRi[..., 1, 2] = 2*qC*qD - 2*qA*qB\n",
    "        delRi[..., 2, 0] = 2*qB*qD - 2*qA*qC\n",
    "        delRi[..., 2, 1] = 2*qC*qD + 2*qA*qB\n",
    "        delRi[..., 2, 2] = qA**2 - qB**2 - qC**2 + qD**2\n",
    "\n",
    "        Ri = torch.einsum(\"bnij, bnjk->bnik\", delRi, R_in)\n",
    "        Ti = delTi + T_in\n",
    "\n",
    "        alpha = self.sc_predictor(msa[:, 0], state)\n",
    "\n",
    "        return Ri, Ti, state, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "cac6620e-d6bc-4143-a8b8-0bf99ea62785",
   "metadata": {},
   "outputs": [],
   "source": [
    "str2str_m = Str2Str_mannual(d_msa=d_msa_full, \n",
    "                  d_pair=d_pair,\n",
    "                   d_state=8,\n",
    "                   SE3_param=SE3_param_full,\n",
    "                   p_drop=p_drop).to(device)\n",
    "\n",
    "\n",
    "R_m, T_m, state_m, alpha_m = str2str(msa_, pair, R_in, T_in, xyz, state, idx_pdb[:, :10], motif_mask=motif_mask, top_k=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a569ec5-7ead-4e51-809c-38759ab22c30",
   "metadata": {},
   "source": [
    "* In the above code, the authors use quaternion to construct rotation matrix. For a primer on quaternions and their role in 3D rotations, refer to  **[here](https://github.com/kilianmandon/alphafold-decoded/blob/main/tutorials/geometry/geometry.ipynb)** to learn the basics of quaternion and how it works.\n",
    "* Within the SE(3)-Transformer framework, unit quaternions are generated to represent rotations, ensuring that both the SE(3) transformations and the quaternion-based rotations are equivariant—a key property for maintaining geometric consistency in 3D deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629ef52-9855-450c-888a-7f81f4194883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
